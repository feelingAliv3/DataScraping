{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steganography and Steganalysis (with GPU)\n",
    "Steganography is the art of hiding information (super secrets !) in an image or text, whereas steganalysis is the art of uncoverting that information. To understand, steganography, I have attached the following youtube video from the Computerphile channel (very cool channel !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"http://www.youtube.com/embed/TWEXCYQKyDc\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"http://www.youtube.com/embed/TWEXCYQKyDc\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of methods to embed information/messages into a text/images. For a JPEG image, one method is to embed information in the discrete cosine transformation (DCT). \n",
    "\n",
    "1. First, the RGB channel space is converted to YUV/YCbCr channel space (because human eyes cannot distinguish CbCr well).\n",
    "2. After converting the color space, an 8x8 kernel is applied to the image. This 8x8 kernel contains both low and high frequency cosine function in the x-y direction (i.e. each cell in the 64 (8x8) contains a custom $cos(2 \\pi x) + cos(2 \\pi y)$) and is being convoluted across the x-y direction on the image and across the image channel. The resultant image is a 512 x 512 x 3 float value\n",
    "3. A 8x8 quantization table is applied to the resultant image. This 8x8 table is used as a quotient, specifically the float value are divided by this \"custom\" integer table. Hence, hiding information.\n",
    "4. In order to reverse the process, the \"custom\" quantization table is needed to decode the message.\n",
    "\n",
    "There are more sophisticated method to generation of the quantization table (value distribution (usually gaussian), dimension and etc)\n",
    "\n",
    "More information can be found here (https://www.kaggle.com/prashant111/alaska2-image-steganalysis-all-you-need-to-know)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interest for steganography and steganalysis stems from an ongoing (as of May 7th 2020) Kaggle competition (https://www.kaggle.com/c/alaska2-image-steganalysis). The dataset can be found in the website after agreements to the terms and conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Managing dataset\n",
    "The provided dataset has 4 folders (corresponding to 1 negative and 3 positives labels). Each folder contains 75,000 images per folder. Each image is 512 x 512 x 3. The resulting dataset is approximately 35gb. We start off by overfitting a smaller sample size, then gradually adding more training samples to regularize and generalize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "types = [\"Cover\",\"JMiPOD\",\"JUNIWARD\",\"UERD\"]\n",
    "PATH = r\"C:\\Users\\Innovations\\Desktop\\AI\\Steganography\\Data\"\n",
    "data_paths = [os.listdir(os.path.join(PATH, alg)) for alg in types]\n",
    "\n",
    "# another approach is to use np.random.shuffle(os.listdir(directory) and use index slicing to get desired sample size)\n",
    "for index, folder in enumerate(data_paths):\n",
    "    print(index)\n",
    "    for file in folder:\n",
    "        if abs(np.random.rand(1)) < 0.1:\n",
    "            if index == 0:\n",
    "                shutil.copyfile(PATH + '/'+ types[index] + \"/\" + file, PATH + '/'+ 'miniCover'+ '/' + file)\n",
    "            elif index == 1:\n",
    "                shutil.copyfile(PATH + '/'+ types[index] + \"/\" + file, PATH + '/'+ 'miniJMiPOD'+ '/'+ file)\n",
    "            elif index == 2:\n",
    "                shutil.copyfile(PATH + '/'+ types[index] + \"/\" + file, PATH + '/'+ 'miniJUNIWARD'+ '/' + file)\n",
    "            elif index == 3:\n",
    "                shutil.copyfile(PATH + '/'+ types[index] + \"/\" + file, PATH + '/'+ 'miniUERD'+ '/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Definition\n",
    "Here, we build the Deep Residual Network based on the works by Mehdi et. al. (2017)(http://www.ws.binghamton.edu/fridrich/Research/SRNet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Add, AveragePooling2D, GlobalAveragePooling2D, Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer1(inputLayer, noFilter, filterSize=(8,8), strides=(1,1), padding = \"same\"):\n",
    "    x = Conv2D(noFilter, filterSize, strides, paadding)(inputLayer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def layer2(inputLayer, noFilter, filterSize1=(8,8), filterSize2=(8,8), strides1=(1,1), strides2=(1,1), padding = \"same\"):\n",
    "    x = layer1(inputLayer, noFilter, filterSize1, strides1, padding)\n",
    "    x = Conv2D(noFilter, filterSize2, strides2, padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, inputLayer])\n",
    "\n",
    "    return x\n",
    "\n",
    "def layer3(inputLayer, noFilter, filterSize1=(8,8), filterSize3=(8,8), strides1=(1,1), strides3=(1,1), padding = \"same\"):\n",
    "    x1 = layer1(inputLayer, noFilter, filterSize1, strides1, padding)\n",
    "    x1 = Conv2D(noFilter, filterSize3, strides3, padding)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = AveragePooling2D(pool_size=(3,3), strides =(2,2))(x1)\n",
    "    \n",
    "    x2 = Conv2D(noFilter, (3,3), (2,2))(inputLayer)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "\n",
    "    x = Add()([x1,x2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def layer4(inputLayer, noFilter, filterSize1=(8,8), filterSize4=(8,8), strides1=(1,1), strides4=(1,1), padding = \"same\"):\n",
    "    x = layer1(inputLayer, noFilter, filterSize1, strides1, padding)\n",
    "    x = Conv2D(noFilter, filterSize4, strides4, padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build(width, height, depth, noClasses):\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    if K.image_data_format == \"channel_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "\n",
    "    inputs = Input(shape = inputShape)\n",
    "\n",
    "    x = layer1(inputs, 64)\n",
    "    x = layer1(x,16)\n",
    "\n",
    "    x = layer2(x,16)\n",
    "    x = layer2(x,16)\n",
    "    x = layer2(x,16)\n",
    "    x = layer2(x,16)\n",
    "    x = layer2(x,16)\n",
    "    \n",
    "    x = layer3(x,16)\n",
    "    x = layer3(x,32)\n",
    "    x = layer3(x,64)\n",
    "    x = layer3(x,128)\n",
    "\n",
    "#     x = layer4(x,512)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build(512,512,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 64) 12352       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 16) 65552       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 16) 16400       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 512, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 16) 16400       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 512, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 512, 16) 0           batch_normalization_3[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 512, 512, 16) 16400       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512, 512, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 512, 512, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 512, 512, 16) 16400       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512, 512, 16) 64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 512, 16) 0           batch_normalization_5[0][0]      \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 512, 16) 16400       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 512, 16) 64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512, 512, 16) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 512, 16) 16400       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512, 512, 16) 64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512, 512, 16) 0           batch_normalization_7[0][0]      \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 512, 512, 16) 16400       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 512, 512, 16) 64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512, 512, 16) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 512, 512, 16) 16400       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 512, 512, 16) 64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 16) 0           batch_normalization_9[0][0]      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 512, 16) 16400       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 512, 512, 16) 64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 512, 512, 16) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 512, 512, 16) 16400       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 512, 16) 64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 512, 16) 0           batch_normalization_11[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 512, 512, 16) 16400       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512, 512, 16) 64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 512, 512, 16) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 512, 512, 16) 16400       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 512, 512, 16) 64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 255, 255, 16) 2320        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 255, 255, 16) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 255, 255, 16) 64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 255, 255, 16) 0           average_pooling2d[0][0]          \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 255, 255, 32) 32800       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 255, 255, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 255, 255, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 255, 255, 32) 65568       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 255, 255, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 127, 127, 32) 4640        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 127, 127, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 127, 127, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 127, 127, 32) 0           average_pooling2d_1[0][0]        \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 127, 127, 64) 131136      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 127, 127, 64) 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 127, 127, 64) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 127, 127, 64) 262208      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 127, 127, 64) 256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 63, 63, 64)   18496       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 63, 63, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 63, 63, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 63, 63, 64)   0           average_pooling2d_2[0][0]        \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 63, 63, 128)  524416      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 63, 63, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 63, 63, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 63, 63, 128)  1048704     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 63, 63, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 31, 31, 128)  73856       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 31, 31, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 31, 31, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 31, 31, 128)  0           average_pooling2d_3[0][0]        \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 128)          0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           4128        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,446,849\n",
      "Trainable params: 2,444,929\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare dataset for Pipeline intake\n",
    "There are two approaches to preparing the dataset for intake.\n",
    "(a) import image into memory (but significantly smaller dataset can be ingested, due to limitation on CPU and memory limit)\n",
    "(b) leverage keras image data generator to build an input pipeline that flows from the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a : In-Memory Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "IMG_SIZE = 512\n",
    "PATH = r\"C:\\Users\\Innovations\\Desktop\\AI\\Steganography\\Data\"\n",
    "test_images_path = [os.path.join(PATH,\"Test\",i) for i in os.listdir(r\"C:\\Users\\Innovations\\Desktop\\AI\\Steganography\\Data\\Test\")]\n",
    "ALGORITHMS = ['JMiPOD','JUNIWARD','UERD']\n",
    "\n",
    "def load_image(data):\n",
    "    i, j, img_path, labels = data\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    label = labels[i][j]\n",
    "    \n",
    "    return [np.array(img), label]\n",
    "\n",
    "def load_training_data_multi(n_images=100):\n",
    "    train_data = []\n",
    "    data_paths = [os.listdir(os.path.join(PATH, alg)) for alg in ['Cover'] + ALGORITHMS]\n",
    "    print(data_paths)\n",
    "    labels = [np.zeros(n_images), np.ones(n_images), np.ones(n_images), np.ones(n_images)]\n",
    "\n",
    "    for i, image_path in enumerate(data_paths):\n",
    "        \n",
    "        train_data_alg = joblib.Parallel(n_jobs=4, backend='threading')(\n",
    "            joblib.delayed(load_image)([i, j, os.path.join(PATH, [['Cover'] + ALGORITHMS][0][i], img_p), labels]) for j, img_p in enumerate(image_path[:n_images]))\n",
    "\n",
    "        train_data.extend(train_data_alg)\n",
    "        \n",
    "    shuffle(train_data)\n",
    "    return train_data\n",
    "\n",
    "def load_test_data():\n",
    "    test_data = []\n",
    "    for img in test_images_path:\n",
    "        img = cv2.imread(img)\n",
    "        img = cv2.resize(img, (512, 512))\n",
    "        test_data.append([np.array(img)])\n",
    "            \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 2000 6000 2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_data = load_training_data_multi(n_images=2000)\n",
    "trainImages = np.array([i[0] for i in training_data])\n",
    "trainLabels = np.array([i[1] for i in training_data])\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainImages, trainLabels, random_state=42)\n",
    "print(len(X_train), len(X_val), len(y_train), len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b : ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# limited by GPU memory size\n",
    "BATCH_SIZE=8\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=90)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_path = r\"C:\\Users\\Innovations\\Desktop\\AI\\Steganography\\Data\\train\"\n",
    "train_generator = train_datagen.flow_from_directory(train_path, target_size=(512,512), batch_size=BATCH_SIZE, class_mode=\"binary\", classes=[\"0\", \"1\"], subset=\"training\")\n",
    "valid_generator = train_datagen.flow_from_directory(train_path, target_size=(512,512), batch_size=BATCH_SIZE, class_mode=\"binary\", classes=[\"0\", \"1\"], subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2/10),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom callbacks to save model for future training and learning rate scheduler on validation dataset's loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "class EpochCheckpoint(Callback):\n",
    "    def __init__(self, outputPath, every=3, startAt=0):\n",
    "        super(Callback, self).__init__()\n",
    "        \n",
    "        self.outputPath = outputPath\n",
    "        self.every = every\n",
    "        self.intEpoch = startAt\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (self.intEpoch + 1) % self.every == 0:\n",
    "            p = os.path.sep.join([self.outputPath, \"SRNet_epoch_{}.hdf5\".format(self.intEpoch+1)])\n",
    "            self.model.save(p, overwrite=True)\n",
    "            \n",
    "        self.intEpoch +=1\n",
    "        \n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Model\n",
    "### Step 4a: Train Model with a smaller but augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 750 steps, validate for 250 steps\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 1505s 2s/step - loss: 0.5901 - accuracy: 0.7335 - val_loss: 0.5561 - val_accuracy: 0.7430\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 1493s 2s/step - loss: 0.5310 - accuracy: 0.7593 - val_loss: 0.5468 - val_accuracy: 0.7655\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 1493s 2s/step - loss: 0.5194 - accuracy: 0.7655 - val_loss: 0.5241 - val_accuracy: 0.7720\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 1493s 2s/step - loss: 0.5126 - accuracy: 0.7640 - val_loss: 0.5409 - val_accuracy: 0.7690\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 1497s 2s/step - loss: 0.5032 - accuracy: 0.7685 - val_loss: 0.6283 - val_accuracy: 0.7075\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 1494s 2s/step - loss: 0.4988 - accuracy: 0.7690 - val_loss: 0.4752 - val_accuracy: 0.7800\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 1517s 2s/step - loss: 0.4959 - accuracy: 0.7700 - val_loss: 0.5052 - val_accuracy: 0.7750\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 1504s 2s/step - loss: 0.4904 - accuracy: 0.7740 - val_loss: 0.5194 - val_accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 1549s 2s/step - loss: 0.4890 - accuracy: 0.7747 - val_loss: 0.4992 - val_accuracy: 0.7775\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 1554s 2s/step - loss: 0.4819 - accuracy: 0.7725 - val_loss: 0.4976 - val_accuracy: 0.7745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16252f3ad48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(train_datagen.flow(X_train, y_train, batch_size=8), validation_data = train_datagen.flow(X_val, y_val, batch_size=8), class_weight = class_weights, epochs = 10, shuffle=True, callbacks = [reduce_lr])\n",
    "model.fit(train_datagen.flow(X_train, y_train, BATCH_SIZE), validation_data = valid_datagen.flow(X_val, y_val, BATCH_SIZE), steps_per_epoch = 6000 // BATCH_SIZE, validation_steps = 2000 // BATCH_SIZE, epochs = 10, shuffle=True, callbacks = [EpochCheckpoint(r\"C:\\Users\\Innovations\\Desktop\\AI\\Steganography\", every=5, startAt=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4b: Train Model with ImageDataGenerator, with data directly from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, steps_per_epoch=(?)//BATCH_SIZE, epochs=10, validation_data=valid_generator, validation_steps= (?)//BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "PATH = r\"C:\\Users\\Innovations\\Desktop\\AI\\Steganography\\Data\"\n",
    "\n",
    "sample_sub = pd.read_csv(PATH + '\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test = load_test_data()\n",
    "ckptmodel = tf.keras.models.load_model(\"SRNet_epoch_10.hdf5\")\n",
    "test_images = np.array([i[0] for i in test]).astype(\"float\")\n",
    "test_images /= 255.0\n",
    "predict = ckptmodel.predict(test_images, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['Label'] = predict\n",
    "sample_sub.to_csv('submission (SRNet512).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the SRNET512 and 8000 sample size, the submission yields a score of **0.568**. Some authors have found better success with a different network architecture (EfficientNet B7 and InceptionNetV2). Unfortunately, due to the number of network parameters and image size, large amount of computations are required. A google colab effort will be used moving forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
